```markdown
**DAY 1/21: Environment Setup & Generating Synthetic Book Data ðŸ“š**  

Today I set up my development environment and took my first step into data generation â€” starting with synthetic book data for the fictional *Page Turner Analytics*. This was the foundation for everything that follows in the bootcamp.  

ðŸŽ¯ **Key Takeaway:** A clean, well-prepared environment saves hours of debugging later and makes experimentation seamless.  

ðŸ’» **What I Built:**  
I generated a small dataset mimicking bookstore inventory â€” titles, authors, genres, prices, and stock counts â€” using Python and Pandas. The data was bundled into a DataFrame and exported to CSV for future analysis. Creating synthetic data gave me a safe sandbox to practice data manipulation without worrying about sensitive, real-world data.  

```python
import pandas as pd  

data = {
    "Title": ["Book A", "Book B", "Book C"],
    "Author": ["Author X", "Author Y", "Author Z"],
    "Price": [12.99, 9.99, 15.50]
}

df = pd.DataFrame(data)
df.to_csv("books.csv", index=False)
```

ðŸ“ˆ **Progress:** 4% through the bootcamp â€” small step, but a big foundation.  

ðŸš€ **Tomorrow:** Diving into *DataFrame Basics* â€” creating and inspecting data.  

ðŸ’¬ **Question for you:** How do you approach generating synthetic data for your projects â€” randomization, pattern-based, or realistic samples?  

#100DaysOfCode #DataScience #Python #Pandas #Dash #DataVisualization #Day1of21
```